https://medium.com/swlh/5-free-online-courses-to-learn-big-data-hadoop-and-spark-in-2019-a553e6ccfe30

https://www.udemy.com/course/hadoopstarterkit/learn/lecture/2995888#overview

https://solutionsreview.com/business-intelligence/the-best-apache-spark-courses-and-online-training/

Hadoop:
  MapReduce is a programming model for distributed computing.It is a programming model which you can use to process huge datasets in a distributed fashion. If you want to use Map and Reducer in Hadoop, you need to learn some programming languages to process data, for example Java, Python and Scala.

  Apache Pig is developed by Yahoo. It is designed to make matters accessible to anyone who want to work with Hadoop cluster. Pig is heavily used in the industry and it is the top skill need to grasp if want to get a job in Hadoop industry. It is very similar to SQL.

  All the datasets in Hadooo and Pig are in file format, not in table structure. Hive is developed to overcome this disadvantage.

  Apache Hive is developed by Facebook and it is now a top level Apache project. You can create table stuructures for your own dataset and then write SQL like queries to analyze the data.

  Hive and Pig can be used at the same time for a project even though they have similar functions. Pig can be used for standard nightly ETL kind of jobs like extracting data, transforming the data, loading the data and doing some predefined aggregations. Hive can be used by developers, data analyst and data scientist on a day to day basis for ad hoc analysis of data.

  Yarn is a resource management tool.
  
  
Spark:

